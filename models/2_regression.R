# Libs --------------------------------------------------------------------

library(tidyverse)
library(mlr)
library(parallel)

# Data --------------------------------------------------------------------

load(here::here("models/seizures_normalized_c3.RData"))

rdesc <- makeResampleDesc("Subsample",
  iters = 50, predict = "both", stratify = TRUE
)
ps = makeParamSet(makeDiscreteParam("link", "logit"))
ctrl = makeTuneControlGrid(tune.threshold = TRUE, resolution = 1)
lrn = makeLearner("classif.binomial",
                  predict.type = "prob",
                  id = "logreg")

# Analysis ----------------------------------------------------------------
chunk_size <- 200
chunks <-
  c(
    combn(ncol(dataset) - 1, 1, simplify = FALSE),
    combn(ncol(dataset) - 1, 2, simplify = FALSE),
    combn(ncol(dataset) - 1, 3, simplify = FALSE)
  ) %>%
  lapply(function(y) {
    c(y, ncol(dataset))
  }) %>%
  sample() %>% # shuffle
  split(rep(1:ceiling(length(.) / chunk_size), each = chunk_size)[1:length(.)])

# Multicore backend
gc()
cl <- makeForkCluster(40)

models <-
  chunks %>%
  names() %>%
  parLapplyLB(cl, ., function(chunk) {
  # pbapply::pblapply(function(chunk) { # for debugging
    headers <-
      structure(list(features = character(0), n = integer(0), thr = numeric(0), 
                     mcc.test.mean = numeric(0), mmce.test.mean = numeric(0), 
                     npv.test.mean = numeric(0), ppv.test.mean = numeric(0)),
                row.names = c(NA, 0L),
                class = c("tbl_df", "tbl", "data.frame"))
    write_csv(
      headers,
      paste0("/mnt/epistop/chunk_", str_pad(chunk, 3, pad = "0"), ".csv")
    )
    lapply(chunks[[chunk]], function(combo) {
      mlr_data <-
        dataset[, combo] %>%
        filter(complete.cases(.)) %>%
        as.data.frame()
      clasif.task <-
        makeClassifTask(
          id = "regression",
          data = mlr_data,
          target = "seizures_any",
          positive = "TRUE"
        )
      tune.pars = tuneParams(learner = lrn, task = clasif.task, resampling = rdesc,
                             measures = list(mcc, ppv, npv, mmce), par.set = ps,
                             control = ctrl, show.info = FALSE)
      row <-
        tibble(
          features = paste(names(mlr_data)[-ncol(mlr_data)], collapse = " + "),
          n = nrow(mlr_data),
          thr = tune.pars$threshold
        ) %>% 
        bind_cols(
          tune.pars$y %>% 
            enframe %>%
            spread(name, value)
        )
      write_csv(row,
        paste0("/mnt/epistop/chunk_", str_pad(chunk, 3, pad = "0"), ".csv"),
        append = TRUE
      )
      return(row)
    })
  })

# Multicore off
stopCluster(cl)
rm(cl)
gc()

# models_stats <-
#   lapply(models, bind_rows) %>%
#   bind_rows(.id = "scheme") %>%
#   arrange(mmce)

# write_csv(models_stats, here::here("models/lm_stats.csv"))
